## Introduction


Ce projet a pour objectif de mettre en place une solution d'intelligence artificielle générative en auto-hébergement. Il s'appuie sur deux composants principaux :

- Ollama : un outil permettant de télécharger, gérer et exécuter localement des modèles de langage (LLMs).

- Open WebUI : une interface web moderne et intuitive pour interagir avec ces modèles en toute simplicité.

Cette plateforme permet à un utilisateur de poser des questions en langage naturel et d'obtenir des réponses cohérentes, contextuelles, et intelligentes, sans dépendre de services cloud externes.

## Qu'est-ce qu'un LLM ?

Un LLM (ou modèle de langage à grande échelle) est un modèle d’intelligence artificielle entraîné sur d’énormes volumes de texte. Ces modèles apprennent les structures, relations, et significations dans le langage humain. Une fois entraîné, un LLM est capable de :

- Comprendre et générer du texte en langage naturel

- Répondre à des questions, traduire des textes, résumer des documents

- Simuler une conversation naturelle, écrire du code, etc.

Les modèles les plus connus aujourd'hui sont GPT-3, GPT-4, LLaMA (Meta), Mistral, etc. Ces modèles contiennent des milliards de paramètres : ce sont des fonctions mathématiques ajustées pendant l'entraînement pour prédire le mot suivant dans une phrase.

Par exemple :

**Entrée** : *"Le ciel est bleu parce que..."*

**Sortie :** *"...la lumière du soleil est diffusée par l’atmosphère terrestre."*

## Pourquoi utiliser Ollama et Open WebUI ?

Ollama permet d'exécuter localement les LLMs, sans envoyer vos données vers un serveur distant.

Open WebUI fournit une interface élégante pour discuter avec ces modèles, comparable à ChatGPT, mais auto-hébergée, respectueuse de la vie privée et entièrement personnalisable.

Ce projet est donc une alternative locale, libre et extensible aux assistants IA disponibles sur Internet.

